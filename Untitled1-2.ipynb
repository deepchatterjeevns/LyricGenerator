{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[93m    Warning: no model found for 'en'\u001b[0m\n",
      "\n",
      "    Only loading the 'en' tokenizer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.learner import *\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "import dill as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='/home/ubuntu/fastai/courses/dl1/'\n",
    "TRN_PATH = '/home/ubuntu/fastai/courses/dl1/Pop_train.txt'\n",
    "VAL_PATH = '/home/ubuntu/fastai/courses/dl1/Pop_test.txt'\n",
    "Train_data = !cat {Train_Path}\n",
    "Test_data = !cat {Test_Path}\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "#import pandas as pd\n",
    "#from sklearn.utils import shuffle\n",
    "#df = pd.read_csv('/home/ubuntu/fastai/courses/dl1/billboard_lyrics_1964-2015.csv')\n",
    "#type(df)\n",
    "#df = df[df['Lyrics'].notnull()]\n",
    "#df2 = df['Lyrics']\n",
    "#df2 = shuffle(df2)\n",
    "#df2=df2.reset_index(drop=True)\n",
    "#len_ds = len(df2)\n",
    "#len_train=int(0.8*len_ds)\n",
    "#df_train = df2[:len_train]\n",
    "#df_test = df2[len_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat {TRN_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#from sklearn.utils import shuffle\n",
    "#df = pd.read_csv('/home/ubuntu/fastai/courses/dl1/billboard_lyrics_1964-2015.csv')\n",
    "#type(df)\n",
    "#df = df[df['Lyrics'].notnull()]\n",
    "#df2 = df['Lyrics']\n",
    "#df2 = shuffle(df2)\n",
    "#df2=df2.reset_index(drop=False)\n",
    "#len_ds = len(df2)\n",
    "#len_train=int(0.8*len_ds)\n",
    "#df_train = df2[:len_train]\n",
    "#df_test = df2[len_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=spacy_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=64; bptt=70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=10)\n",
    "#md = LanguageModelData.from_dataframes(PATH, TEXT, df_train ,df_test,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(TEXT, open(f'{PATH}/TEXT.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "billboard_lyrics_1964-2015.csv\tnasnet.ipynb\r\n",
      "cifar10.ipynb\t\t\tnlp-arxiv.ipynb\r\n",
      "Country_test.txt\t\tnlp.ipynb\r\n",
      "Country_train.txt\t\tplanet_cv.ipynb\r\n",
      "data\t\t\t\tplanet.py\r\n",
      "excel\t\t\t\tPop_test.txt\r\n",
      "fastai\t\t\t\tPop_train1.txt\r\n",
      "fish.ipynb\t\t\tPop_train.txt\r\n",
      "images\t\t\t\tPreprocess.ipynb\r\n",
      "keras_lesson1.ipynb\t\tRishi.ipynb\r\n",
      "lang_model-arxiv.ipynb\t\trossman_exp.py\r\n",
      "lang_model.ipynb\t\tscripts\r\n",
      "lesson1.ipynb\t\t\ttest_transforms.ipynb\r\n",
      "lesson1-rxt50.ipynb\t\tTest.txt\r\n",
      "lesson1-sgd.ipynb\t\tTEXT.pkl\r\n",
      "lesson1-vgg.ipynb\t\ttmp\r\n",
      "lesson2-image_models.ipynb\tTrain.txt\r\n",
      "lesson3-rossman.ipynb\t\tUntitled1.ipynb\r\n",
      "lesson4-imdb.ipynb\t\tUntitled2.ipynb\r\n",
      "lesson5-movielens.ipynb\t\tUntitled.ipynb\r\n",
      "models\r\n"
     ]
    }
   ],
   "source": [
    "!ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(597, 7663, 1, 2682403)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz = 200  # size of each embedding vector\n",
    "nh = 250#500     # number of hidden activations per layer\n",
    "nl = 3       # number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = md.get_model(opt_fn, em_sz, nh, nl,\n",
    "               dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n",
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learner.clip=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef63d72068ad40c98af3bae53a974058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.       5.33582  5.20024]                                \n",
      "[ 1.       4.88672  4.79015]                                \n",
      "[ 2.       4.71025  4.67154]                                \n",
      "[ 3.      4.5872  4.5754]                                   \n",
      "[ 4.       4.37113  4.44869]                                \n",
      "[ 5.       4.22731  4.38909]                                \n",
      "[ 6.       4.17049  4.36377]                                \n",
      "[ 7.       4.23515  4.41535]                                \n",
      "[ 8.       4.09354  4.37585]                                \n",
      "[ 9.       3.97444  4.34553]                                \n",
      "[ 10.        3.87125   4.31838]                             \n",
      "[ 11.        3.81844   4.29439]                             \n",
      "[ 12.        3.73292   4.27785]                             \n",
      "[ 13.        3.74693   4.25425]                             \n",
      "[ 14.        3.74357   4.2605 ]                             \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.fit(3e-3, 4, wds=1e-6, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner.save_encoder('adam1_enc')\n",
    "#learner.fit(3e-3, 4, wds=1e-6, cycle_len=10, cycle_save_name='adam3_10')\n",
    "#learner.fit(3e-3, 1, wds=1e-6, cycle_len=20, cycle_save_name='adam3_20')\n",
    "#math.exp(4.165)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I 've been reading books of old legends and myth .\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss=\"\"\"I've been reading books of old legends and myth. \"\"\"\n",
    "s = [spacy_tok(ss)]\n",
    "t=TEXT.numericalize(s)\n",
    "' '.join(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = learner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size to 1\n",
    "m[0].bs=1\n",
    "# Turn off dropout\n",
    "m.eval()\n",
    "# Reset hidden state\n",
    "m.reset()\n",
    "# Get predictions from model\n",
    "res,*_ = m(t)\n",
    "# Put the batch size back to what it was\n",
    "m[0].bs=bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'the',\n",
       " 'in',\n",
       " 'my',\n",
       " 'an',\n",
       " 'on',\n",
       " 'that',\n",
       " 'me',\n",
       " 'be',\n",
       " 'with',\n",
       " 'his',\n",
       " 'somebody',\n",
       " 'everything',\n",
       " 'mine',\n",
       " 'her',\n",
       " 'this',\n",
       " 'just',\n",
       " 'you',\n",
       " 'all',\n",
       " 'some']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nexts = torch.topk(res[-1], 20)[1]\n",
    "[TEXT.vocab.itos[o] for o in to_np(nexts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've been reading books of old legends and myth.  \n",
      "\n",
      "and i m not the one who s gon na be the one who s gon na be the one who s gon na be a good girl with a man who s gon na be a man who s gon na be a man who s gon na be ...\n"
     ]
    }
   ],
   "source": [
    "print(ss,\"\\n\")\n",
    "for i in range(50):\n",
    "    n=res[-1].topk(2)[1]\n",
    "    n = n[1] if n.data[0]==0 else n[0]\n",
    "    print(TEXT.vocab.itos[n.data[0]], end=' ')\n",
    "    res,*_ = m(n[0].unsqueeze(0))\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
